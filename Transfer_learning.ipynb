{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1Y2kysqlU4eMkh83152orf1cCCM4vaqS7",
      "authorship_tag": "ABX9TyM3qXFUB8EzXTEeN23bR6/0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "060541bde736400ea2ff5ed7f7418911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3966456b9494b2da85b69f53565c2cf",
              "IPY_MODEL_49d09541a5fe4937bf4557a30f590fe4",
              "IPY_MODEL_f58c6c84132846f3a023e98c5414d854"
            ],
            "layout": "IPY_MODEL_5891365ce6884e89893470ee2ff3f079"
          }
        },
        "c3966456b9494b2da85b69f53565c2cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3467ef5a3c80466e9573d7973b13a022",
            "placeholder": "​",
            "style": "IPY_MODEL_1ab0d692cdfa4f91a8493cbe55912a6a",
            "value": "100%"
          }
        },
        "49d09541a5fe4937bf4557a30f590fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c60176a9d3df4429a9c8de3380511b69",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95e9d2584e554bddab465eca18e8abfa",
            "value": 1
          }
        },
        "f58c6c84132846f3a023e98c5414d854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af5c1369be274f56b0e109f365e4608c",
            "placeholder": "​",
            "style": "IPY_MODEL_fc0386139c8545c5aa0182261c13ab05",
            "value": " 1/1 [32:06&lt;00:00, 1926.49s/it]"
          }
        },
        "5891365ce6884e89893470ee2ff3f079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3467ef5a3c80466e9573d7973b13a022": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ab0d692cdfa4f91a8493cbe55912a6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c60176a9d3df4429a9c8de3380511b69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95e9d2584e554bddab465eca18e8abfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af5c1369be274f56b0e109f365e4608c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc0386139c8545c5aa0182261c13ab05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcabergeron/CNN-Project/blob/main/Transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preparation"
      ],
      "metadata": {
        "id": "PxPJPnaoyd7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"images\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(\"drive/MyDrive/Colab Notebooks/Project_CNN/Images/animal_10 (2).zip\", \"r\") as zip_ref:\n",
        "        print(\"Unzipping animal images...\")\n",
        "        zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frIJoyA_yiMn",
        "outputId": "ce745f93-56d7-46ed-c165-6769efc47f99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not find data/images directory, creating one...\n",
            "Unzipping animal images...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Renaming folders\n",
        "import os\n",
        "\n",
        "translate_path = Path(\"/content/drive/MyDrive/Colab Notebooks/Project_CNN/Images/translate.py\")\n",
        "f = open(translate_path, \"r\")\n",
        "folder_dict = f.readline()\n",
        "f.close()\n",
        "exec(folder_dict)\n",
        "\n",
        "os.chdir('/content/data/images/animal_10 (2)/raw-img')\n",
        "all_subdirs = [d for d in os.listdir('.') if os.path.isdir(d)]\n",
        "\n",
        "for dir in all_subdirs:\n",
        "  if dir in translate.keys():\n",
        "    os.rename(\"/content/data/images/animal_10 (2)/raw-img/\" + dir, \"/content/data/images/animal_10 (2)/raw-img/\" + translate.get(dir))"
      ],
      "metadata": {
        "id": "3pf1yXBbyyA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.remove(\"/content/data/images/animal_10 (2)/raw-img/.DS_Store\")"
      ],
      "metadata": {
        "id": "2qGuyEudy5Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting folders in train and test\n",
        "!pip install split-folders\n",
        "import splitfolders\n",
        "splitfolders.ratio('/content/data/images/animal_10 (2)/raw-img', output=\"/content/data/images/animal_10 (2)\", seed=42, ratio=(.8, 0.0,0.2\n",
        "                                                                                                  ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eCMQBKOy7yM",
        "outputId": "28013b2b-00ba-4b34-9c6f-15954993b6b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 26179 files [00:08, 3175.71 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initializing train and test dir\n",
        "train_dir = \"/content/data/images/animal_10 (2)/train\"\n",
        "test_dir = \"/content/data/images/animal_10 (2)/test\""
      ],
      "metadata": {
        "id": "N3-DJKTJzNKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transfer learning"
      ],
      "metadata": {
        "id": "oGJdS-VoqTt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "!pip install -q torchinfo\n",
        "from torchinfo import summary\n"
      ],
      "metadata": {
        "id": "AibEkXrSqucl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alexnet"
      ],
      "metadata": {
        "id": "6zOAB1BlqYzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting model with pre-trained weights"
      ],
      "metadata": {
        "id": "Lud-5GDcqeCg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80H8xU-5qR-J",
        "outputId": "8dd70339-1eba-47aa-ed49-bdc68d2b6340"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet_Weights.IMAGENET1K_V1"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "weights = torchvision.models.AlexNet_Weights.DEFAULT\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Alexnet_transform = weights.transforms()\n",
        "Alexnet_transform"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQas13q5rGHW",
        "outputId": "2eeedcf5-f634-4dea-b090-e1cb0f1bcf3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageClassification(\n",
              "    crop_size=[224]\n",
              "    resize_size=[256]\n",
              "    mean=[0.485, 0.456, 0.406]\n",
              "    std=[0.229, 0.224, 0.225]\n",
              "    interpolation=InterpolationMode.BILINEAR\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.alexnet(weights=weights).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDDJYwmpsDqU",
        "outputId": "fec30fdc-2ffb-4f7f-cb28-ea19c8ed2c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:03<00:00, 64.3MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a summary using torchinfo (uncomment for actual output)\n",
        "summary(model=model,\n",
        "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
        "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awpPUBjvtpBz",
        "outputId": "1df16e1c-a3e1-4268-c624-1f6e73f336ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "========================================================================================================================\n",
              "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
              "========================================================================================================================\n",
              "AlexNet (AlexNet)                        [32, 3, 224, 224]    [32, 1000]           --                   True\n",
              "├─Sequential (features)                  [32, 3, 224, 224]    [32, 256, 6, 6]      --                   True\n",
              "│    └─Conv2d (0)                        [32, 3, 224, 224]    [32, 64, 55, 55]     23,296               True\n",
              "│    └─ReLU (1)                          [32, 64, 55, 55]     [32, 64, 55, 55]     --                   --\n",
              "│    └─MaxPool2d (2)                     [32, 64, 55, 55]     [32, 64, 27, 27]     --                   --\n",
              "│    └─Conv2d (3)                        [32, 64, 27, 27]     [32, 192, 27, 27]    307,392              True\n",
              "│    └─ReLU (4)                          [32, 192, 27, 27]    [32, 192, 27, 27]    --                   --\n",
              "│    └─MaxPool2d (5)                     [32, 192, 27, 27]    [32, 192, 13, 13]    --                   --\n",
              "│    └─Conv2d (6)                        [32, 192, 13, 13]    [32, 384, 13, 13]    663,936              True\n",
              "│    └─ReLU (7)                          [32, 384, 13, 13]    [32, 384, 13, 13]    --                   --\n",
              "│    └─Conv2d (8)                        [32, 384, 13, 13]    [32, 256, 13, 13]    884,992              True\n",
              "│    └─ReLU (9)                          [32, 256, 13, 13]    [32, 256, 13, 13]    --                   --\n",
              "│    └─Conv2d (10)                       [32, 256, 13, 13]    [32, 256, 13, 13]    590,080              True\n",
              "│    └─ReLU (11)                         [32, 256, 13, 13]    [32, 256, 13, 13]    --                   --\n",
              "│    └─MaxPool2d (12)                    [32, 256, 13, 13]    [32, 256, 6, 6]      --                   --\n",
              "├─AdaptiveAvgPool2d (avgpool)            [32, 256, 6, 6]      [32, 256, 6, 6]      --                   --\n",
              "├─Sequential (classifier)                [32, 9216]           [32, 1000]           --                   True\n",
              "│    └─Dropout (0)                       [32, 9216]           [32, 9216]           --                   --\n",
              "│    └─Linear (1)                        [32, 9216]           [32, 4096]           37,752,832           True\n",
              "│    └─ReLU (2)                          [32, 4096]           [32, 4096]           --                   --\n",
              "│    └─Dropout (3)                       [32, 4096]           [32, 4096]           --                   --\n",
              "│    └─Linear (4)                        [32, 4096]           [32, 4096]           16,781,312           True\n",
              "│    └─ReLU (5)                          [32, 4096]           [32, 4096]           --                   --\n",
              "│    └─Linear (6)                        [32, 4096]           [32, 1000]           4,097,000            True\n",
              "========================================================================================================================\n",
              "Total params: 61,100,840\n",
              "Trainable params: 61,100,840\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 22.87\n",
              "========================================================================================================================\n",
              "Input size (MB): 19.27\n",
              "Forward/backward pass size (MB): 126.51\n",
              "Params size (MB): 244.40\n",
              "Estimated Total Size (MB): 390.18\n",
              "========================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Adapting model for a 10 classes"
      ],
      "metadata": {
        "id": "_PVnKRC2vRIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "cVL3P-80vbku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Modify the classifier\n",
        "num_classes = 10  # Change this to your number of classes\n",
        "model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXp8u3jUwR1y",
        "outputId": "3dd6812f-316a-4718-bad5-6b5200005f3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preparing datasets and dataloaders"
      ],
      "metadata": {
        "id": "FNMMsOmw8wEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()"
      ],
      "metadata": {
        "id": "gTTomaS586d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = datasets.ImageFolder(root=train_dir, transform=Alexnet_transform)\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=Alexnet_transform)"
      ],
      "metadata": {
        "id": "pHEcOiEi8-bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset,\n",
        "                                     batch_size=BATCH_SIZE,\n",
        "                                     num_workers=NUM_WORKERS,\n",
        "                              )\n",
        "\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                                    batch_size=BATCH_SIZE,\n",
        "                                    shuffle=False,\n",
        "                                    num_workers=NUM_WORKERS)"
      ],
      "metadata": {
        "id": "hIkKeBzZ9B3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training the model"
      ],
      "metadata": {
        "id": "JN0A51jcxEka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "NUM_EPOCHS = 1"
      ],
      "metadata": {
        "id": "Sec8BaSGx1zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_size = len(train_loader)"
      ],
      "metadata": {
        "id": "-4CfQjDPWaNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = NUM_EPOCHS\n",
        "\n",
        "train_loss_plot = []\n",
        "train_acc_plot = []\n",
        "test_loss_plot = []\n",
        "test_acc_plot = []\n",
        "\n",
        "# Create training and testing loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    print(f\"Epoch: {epoch}\\n-------\")\n",
        "    ### Training\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    # Put model in train mode\n",
        "    model.train()\n",
        "    # Add a loop to loop through training batches\n",
        "    for batch, (X, y) in enumerate(train_loader):\n",
        "\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "      y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate loss (per batch)\n",
        "      loss = loss_fn(y_pred, y)\n",
        "      train_loss += loss # accumulatively add up the loss per epoch\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "      loss.backward()\n",
        "        # 5. Optimizer step\n",
        "      optimizer.step()\n",
        "\n",
        "        # Calculate and accumulate accuracy metrics across all batches\n",
        "      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    train_loss = train_loss / len(train_loader)\n",
        "    train_acc = train_acc / len(train_loader)\n",
        "\n",
        "    ### Testing\n",
        "    # Setup variables for accumulatively adding up loss and accuracy\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in test_loader:\n",
        "          # Send data to target device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred_logits = model(X)\n",
        "\n",
        "            # 2. Calculate loss (accumulatively)\n",
        "            test_loss += loss_fn(test_pred_logits, y) # accumulatively add up the loss per epoch\n",
        "\n",
        "            # 3. Calculate accuracy (preds need to be same as y_true)\n",
        "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    test_loss = test_loss / len(test_loader)\n",
        "    test_acc = test_acc / len(test_loader)\n",
        "\n",
        "\n",
        "    print(f\"\\nTrain loss: {train_loss:.5f} | Train acc:{train_acc:.2f} Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}\\n\")\n",
        "    train_loss_plot.append(train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss)\n",
        "    train_acc_plot.append(train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc)\n",
        "    test_loss_plot.append(test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss)\n",
        "    test_acc_plot.append(test_acc.item()if isinstance(test_acc, torch.Tensor) else test_acc)\n",
        "\n",
        "torch.save(model.state_dict(),\"/content/drive/MyDrive/Colab Notebooks/Project_CNN/Models/Alexnet_transfer_learning_10epchs.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134,
          "referenced_widgets": [
            "060541bde736400ea2ff5ed7f7418911",
            "c3966456b9494b2da85b69f53565c2cf",
            "49d09541a5fe4937bf4557a30f590fe4",
            "f58c6c84132846f3a023e98c5414d854",
            "5891365ce6884e89893470ee2ff3f079",
            "3467ef5a3c80466e9573d7973b13a022",
            "1ab0d692cdfa4f91a8493cbe55912a6a",
            "c60176a9d3df4429a9c8de3380511b69",
            "95e9d2584e554bddab465eca18e8abfa",
            "af5c1369be274f56b0e109f365e4608c",
            "fc0386139c8545c5aa0182261c13ab05"
          ]
        },
        "id": "aisRtJtyxHlV",
        "outputId": "ef64cb69-f71c-4bcd-f929-8904d2efc310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "060541bde736400ea2ff5ed7f7418911"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "-------\n",
            "\n",
            "Train loss: 0.29891 | Train acc:0.93 Test loss: 1.40727, Test acc: 0.61\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluating the model"
      ],
      "metadata": {
        "id": "9rfChmJKxLOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total}')"
      ],
      "metadata": {
        "id": "rII37dvYxOHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG16"
      ],
      "metadata": {
        "id": "DTPjbAMz1CXH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting model"
      ],
      "metadata": {
        "id": "ammV8Mmt1G1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torchvision.models.VGG16_Weights.DEFAULT\n",
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTLEfitv1yq8",
        "outputId": "58919013-4c3b-469a-fec4-03356d87cca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG16_Weights.IMAGENET1K_V1"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VGG16_weights = weights.transforms()\n",
        "VGG16_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uzv-wC0_12NF",
        "outputId": "29d5704c-7a0e-4dd4-e4a8-98190d07bc3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageClassification(\n",
              "    crop_size=[224]\n",
              "    resize_size=[256]\n",
              "    mean=[0.485, 0.456, 0.406]\n",
              "    std=[0.229, 0.224, 0.225]\n",
              "    interpolation=InterpolationMode.BILINEAR\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.vgg16(VGG16_weights)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3NYbpKV2Huh",
        "outputId": "a1d9d67d-885f-411c-a2d1-f28263abd6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:08<00:00, 69.1MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a summary using torchinfo (uncomment for actual output)\n",
        "summary(model=model,\n",
        "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
        "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPOXWjnO3Em7",
        "outputId": "f0394af0-9b70-4a05-97a4-4e0b6ba76628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "========================================================================================================================\n",
              "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
              "========================================================================================================================\n",
              "VGG (VGG)                                [32, 3, 224, 224]    [32, 1000]           --                   True\n",
              "├─Sequential (features)                  [32, 3, 224, 224]    [32, 512, 7, 7]      --                   True\n",
              "│    └─Conv2d (0)                        [32, 3, 224, 224]    [32, 64, 224, 224]   1,792                True\n",
              "│    └─ReLU (1)                          [32, 64, 224, 224]   [32, 64, 224, 224]   --                   --\n",
              "│    └─Conv2d (2)                        [32, 64, 224, 224]   [32, 64, 224, 224]   36,928               True\n",
              "│    └─ReLU (3)                          [32, 64, 224, 224]   [32, 64, 224, 224]   --                   --\n",
              "│    └─MaxPool2d (4)                     [32, 64, 224, 224]   [32, 64, 112, 112]   --                   --\n",
              "│    └─Conv2d (5)                        [32, 64, 112, 112]   [32, 128, 112, 112]  73,856               True\n",
              "│    └─ReLU (6)                          [32, 128, 112, 112]  [32, 128, 112, 112]  --                   --\n",
              "│    └─Conv2d (7)                        [32, 128, 112, 112]  [32, 128, 112, 112]  147,584              True\n",
              "│    └─ReLU (8)                          [32, 128, 112, 112]  [32, 128, 112, 112]  --                   --\n",
              "│    └─MaxPool2d (9)                     [32, 128, 112, 112]  [32, 128, 56, 56]    --                   --\n",
              "│    └─Conv2d (10)                       [32, 128, 56, 56]    [32, 256, 56, 56]    295,168              True\n",
              "│    └─ReLU (11)                         [32, 256, 56, 56]    [32, 256, 56, 56]    --                   --\n",
              "│    └─Conv2d (12)                       [32, 256, 56, 56]    [32, 256, 56, 56]    590,080              True\n",
              "│    └─ReLU (13)                         [32, 256, 56, 56]    [32, 256, 56, 56]    --                   --\n",
              "│    └─Conv2d (14)                       [32, 256, 56, 56]    [32, 256, 56, 56]    590,080              True\n",
              "│    └─ReLU (15)                         [32, 256, 56, 56]    [32, 256, 56, 56]    --                   --\n",
              "│    └─MaxPool2d (16)                    [32, 256, 56, 56]    [32, 256, 28, 28]    --                   --\n",
              "│    └─Conv2d (17)                       [32, 256, 28, 28]    [32, 512, 28, 28]    1,180,160            True\n",
              "│    └─ReLU (18)                         [32, 512, 28, 28]    [32, 512, 28, 28]    --                   --\n",
              "│    └─Conv2d (19)                       [32, 512, 28, 28]    [32, 512, 28, 28]    2,359,808            True\n",
              "│    └─ReLU (20)                         [32, 512, 28, 28]    [32, 512, 28, 28]    --                   --\n",
              "│    └─Conv2d (21)                       [32, 512, 28, 28]    [32, 512, 28, 28]    2,359,808            True\n",
              "│    └─ReLU (22)                         [32, 512, 28, 28]    [32, 512, 28, 28]    --                   --\n",
              "│    └─MaxPool2d (23)                    [32, 512, 28, 28]    [32, 512, 14, 14]    --                   --\n",
              "│    └─Conv2d (24)                       [32, 512, 14, 14]    [32, 512, 14, 14]    2,359,808            True\n",
              "│    └─ReLU (25)                         [32, 512, 14, 14]    [32, 512, 14, 14]    --                   --\n",
              "│    └─Conv2d (26)                       [32, 512, 14, 14]    [32, 512, 14, 14]    2,359,808            True\n",
              "│    └─ReLU (27)                         [32, 512, 14, 14]    [32, 512, 14, 14]    --                   --\n",
              "│    └─Conv2d (28)                       [32, 512, 14, 14]    [32, 512, 14, 14]    2,359,808            True\n",
              "│    └─ReLU (29)                         [32, 512, 14, 14]    [32, 512, 14, 14]    --                   --\n",
              "│    └─MaxPool2d (30)                    [32, 512, 14, 14]    [32, 512, 7, 7]      --                   --\n",
              "├─AdaptiveAvgPool2d (avgpool)            [32, 512, 7, 7]      [32, 512, 7, 7]      --                   --\n",
              "├─Sequential (classifier)                [32, 25088]          [32, 1000]           --                   True\n",
              "│    └─Linear (0)                        [32, 25088]          [32, 4096]           102,764,544          True\n",
              "│    └─ReLU (1)                          [32, 4096]           [32, 4096]           --                   --\n",
              "│    └─Dropout (2)                       [32, 4096]           [32, 4096]           --                   --\n",
              "│    └─Linear (3)                        [32, 4096]           [32, 4096]           16,781,312           True\n",
              "│    └─ReLU (4)                          [32, 4096]           [32, 4096]           --                   --\n",
              "│    └─Dropout (5)                       [32, 4096]           [32, 4096]           --                   --\n",
              "│    └─Linear (6)                        [32, 4096]           [32, 1000]           4,097,000            True\n",
              "========================================================================================================================\n",
              "Total params: 138,357,544\n",
              "Trainable params: 138,357,544\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 495.48\n",
              "========================================================================================================================\n",
              "Input size (MB): 19.27\n",
              "Forward/backward pass size (MB): 3470.52\n",
              "Params size (MB): 553.43\n",
              "Estimated Total Size (MB): 4043.22\n",
              "========================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adapting model"
      ],
      "metadata": {
        "id": "qkvdJGB23eOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Modify the classifier\n",
        "num_classes = 10  # Change this to your number of classes\n",
        "model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn7xfEVh3gvy",
        "outputId": "7c7e3074-4d23-4813-aaa0-03d6cfa7d0f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "tEutyGY93uLX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}